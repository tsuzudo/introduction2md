<!doctype html public "-//w3c//dtd html 4.0 transitional//en">

<html>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<head>
<title>並列計算を行う</title>
<link rel="stylesheet" href="style_ja.css">
</head>

<body>
<center><img src="logo_new.png" alt="Logo" width="600"><br><br><br><h2>並列計算を行う</h2></center><br><br>

<a name="install"><h3>パラレル版のLAMMPS</h3></a>
これまでの講座ではシリアル版のLAMMPSを利用してきた。これは1CPU（厳密には1コア）のみを使う計算法である。LAMMPSの基礎を学ぶにはシリアル版でも十分なことが多いが、それを研究に応用するには限界がある。例えば、多くのケースで大規模シミュレーションが必要となるが、ボックスのサイズを2倍すれば計算時間は少なくとも8倍になってしまうのでそれは簡単ではない。自分が望むサイズにすると計算終了までとんでもない時間がかかってしまうかもしれない。<br><br>

この問題を解決する1つの方法は、多数のコアを同時に利用できる大規模計算機を利用することである。幸い、このような計算機を効率よく利用するため、LAMMPSには並列処理版（パラレル版）が用意されている。具体的には、ボックスをいくつかの領域に分けて、それぞれの領域の処理を異なったコアに割り当てる方式の計算法であり、領域分割法と呼ばれる。当然ながら、利用するコア数が増えればその分計算は速くなる。<br><br>
    
<h3>並列計算法の種類</h3>
パラレル版にはシリアル版では不要だったMessage Passing Interface (MPI)というライブラリが必要になる。これは計算ノードの壁を越えて、異なったCPU間で通信するための枠組みである。MPIはスパコンなどの大規模計算専用のマシーンにはほぼ必ずインストールされている。<br><br>

なお、もう一つのメジャーな並列計算法であるOpenMPは１つの共有メモリが使える範囲内、すなわち1つの計算ノード内での並列計算になり超大規模計算には適していない。LAMMPSでも使えるがあまり恩恵を感じないだろう。<br><br>

Graphics Processing Unit(GPU)を利用する並列計算法もあるが、OpenMPと方法論は似ていて共有メモリを利用する。この方法では原子間ポテンシャルの計算が加速される可能性がある。ただし自分の興味対象にGPU適用可能な原子間ポテンシャルが存在する必要がある。興味のある方は次の講座の<a href="gpu.html">GPUを利用する</a>でさわりだけ述べているので参考にして欲しい。<br><br>

<h3>パラレル版の実行環境</h3>
パラレル版の理想的な実行環境は<b>スーパーコンピューター（スパコン）</b>である。国の研究機関や大学には設置されていることが多く、その中には一般に公開されていて審査を通れば外部の人間も使えるものもある。また、スパコンのリソースを提供する業者も存在する。スパコンでは最大で1万個のコアによる並列計算も可能である。<br><br>

また、研究予算にもよるが、研究室専用の数100コア程度の中規模コンピュータ（<b>クラスター計算機</b>）を導入することもいい選択肢である。<br><br>

<a name="install"><h3>パラレル版のインストール</h3></a>
それらは通常OSとしてLINUXが使われてれているので、 LINUX環境にパラレル版のLAMMPSのインストールしなくてはならない。しかし、一口にLINUX環境といっても様々であるので、そのことがパラレル版のインストールを少し面倒にしている。<br><br>

そもそも、もし研究機関のスパコンを利用するなら、もうすでにコンパイル済の並列処理版LAMMPSがあるかもしれない。なければAdministratorにコンパイル法を相談したり、お願いするという手もある。いずれにれよ、この場合のインストールはスパコンの環境に大きく依存するのでAdministratorとよく相談することだ。<br><br>

クラスター計算機を新たに導入するなら、業者にc++コンパイラ、MPI、パラレル版LAMMPSのインストールを頼んでしまえば簡単だ。<br><br>


さて、ここまでは楽な逃げ道を紹介してきたが、そもそもパラレル版LAMMPSのインストールを自力でやってもそれほど難しいことはない。ただし、様々なケースがあるので、この講座で「この方法で全てうまくいく」という方法を紹介することができない。<br><br>
        
自分の使っていた環境では、IntelのC/C++コンパイラ、IntelのMPI、およびFFT等のライブラリが入っているMath Kernel Library(MKL)があらかじめ使用可能で、スパコンでは典型的な環境だろう。よって、必ずしも受講者の環境と同じとは限らないが、以下に大まかな手順を紹介しておく。<br><br>

まずLAMMPSをダウンロードして展開した後、以下のような手順になる。
<pre>
# cd [lammps top]/src
# make yes-USER-INTEL
# make intel_mpi
</pre>
最初の行で<em>src</em>ディレクトリに移動する。2番目の行ではMKLなどのIntelのライブラリを追加することを指定する。最後の行は全体をコンパイル・ビルドする。因みにこの例では、<em>[lammps top]/src/MAKE</em>の下に<em>Makefile.intel_mpi</em>という名前のMakefileを予め作成してあることが前提である。<br><br>

Makefileというのは大規模コードの複雑なコンパイルを行うための手続きを記述したファイルで、それ専用の言語によって書かれている。Makefileのエキスパートになる必要はないが、大規模コードをコンパイルするにはMakefileの基本的なグラマーは習得しなくてはならない。MAKEディレクトリやそのサブディレクトリのなかに多くのMakefileの例があるので適当なものを少し改良することにより自分用のものとすることができる。決まり切った改良方法はないが、難しいことではない。コンパイルエラーが出た場合はエラーメッセージをよく読み、Makefileをさらに改良する。エラーメッセージをそのままインターネット検索にかけてもいいだろう。大体エラーが出るのはコンパイルのコマンドが違うとか、MPIとかFFTなどのライブラリがパス上に見つからないとかである。無事、コンパイルが成功すればLAMMPSの実行ファイル（実行モジュールとも言う）が<em>src</em>ディレクトリ上にできる。そのファイル名はMakefileのファイル名を使って、この場合なら<em>lmp_intel_mpi</em>となる。<br><br>

以上は自分の知っている環境での話だ。一般的なインストールのやり方は<a href="http://lammps.sandia.gov">公式のLAMMPSのサイト</a>に書いてあるので、それを読み解くしかない。<br><br>

<a name="exec"><h3>パラレル版の実行</h3></a>
次はパラレル版LAMMPSの実行である。通常並列計算機の場合、自分が作業する計算機（作業ノード）と並列計算を行う計算機（並列計算ノード）は分かれていて、作業ノードから並列計算ノードへジョブを<em>submit</em>する（<em>投げる</em>）ことになる。すなわち、並列計算ノードのCPUの全体または一部を占有するための予約を行う。投げられたジョブを行うためのリソースが利用可能な場合には計算は直ちに始まるが、そうでない場合は順番待ちとなる。それはキューイングと呼ばれる。効率的に運営されているスパコンなら、通常計算が開始されるまで数十分程度は待たなくてはならない。<br><br>
研究室内などのローカルな利用者に限定されたクラスター計算機を使っていても、やることは同じである。この場合は自分または同僚が前に投げたジョブが終わり次第、次の計算が開始されることになる。<br><br>

さて、ジョブをsubmitするためにはLINUX上で決まった形式のシェルスクリプトを作成して実行しなくてはならない。ジョブsubmitのためのシェルスクリプトはバッチスクリプトと呼ばれる。計算機によってバッチスクリプトの書き方は異なるがその概念は共通している。Portable Batch System(PBS)は多くの汎用計算機で使われているバッチスクリプトの言語で、以下でそれを使った例を紹介する。

<pre>
#!/bin/sh
#PBS -l nodes=4:ppn=24
#PBS -l walltime=1:00:00
#PBS -N my_lammps
cd $PBS_O_WORKDIR
mpiexec lmp_intel_mpi -in bccFe_anneal.lcm 
</pre>

ここでは1ノードあたり24コアの計算機を想定してる。その中の4ノード（すなわち96コア）を1時間占有するジョブである。オーバヘッドを無視すればシングルコアで4日程度かかる計算を行うことができる。ジョブの識別名はmy_lammpsで、パラレル版LAMMPSを実行される。計算実行は<em>mpiexec</em>コマンド（環境によっては<em>mpijob</em>や<em>mpirun</em>の場合あり）で行う。<br><br><br>

<h3>PCでのパラレル版の利用</h3>
さて、スパコンやクラスター計算機などの大規模な計算機が使えない場合はどうしたらいいだろう。正直、大きな効果は期待できないが自分の事務用PCでも昨今は少なくとも8CPUはある。別に動いているプロセスもあるのですべてのCPUを占有できるわけではないが、少しでも作業を効率化したいなら、そこでパラレル版を利用すべきだ。<br><br>

ちなみにWindowsやMacOSへのインストールは先に説明した<a href="install.html">インストール</a>の講座にもどり、この中のインストール法が紹介されているリンクを参考にすればよい。Macでは初めからMPIが入っており、パラレル版はシリアル版と同時にインストールされるので手間はかからない。<br><br>

実行は上記のジョブsubmitではなくコマンドラインで行う。8並列で計算したいなら以下のようなコマンドラインで実行する。
<pre>
$ mpiexec -np 8 lmp_mpi -in bccFe_anneal.lcm 
</pre>
<br><br><br><br>

<center><a href="index.html">目次へ</a>    前は<a href="read_data.html">LAMMPSの外部で初期値を作る</a>  次は<a href="gpu.html">GPUを利用する</a></pre></center>
<br><br>
</body>
</html>
