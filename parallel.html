<!doctype html public "-//w3c//dtd html 4.0 transitional//en">

<html>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<head>
<title>並列計算を行う</title>
</head>

<body bgcolor="ffffcc">
<center><h2 style="color:Blue;">並列計算を行う</h2></center><br>

<a name="install"><h3 style="color:Blue;">パラレル版のインストール</h3></a>
これまでの講座ではシリアル版のLAMMPSを利用してきた。これは1CPU（厳密には1コア）のみを使う計算法である。LAMMPSの基礎を学ぶにはシリアル版でも十分なことが多いが、それを研究に応用するには限界がある。例えば、多くのケースで大規模シミュレーションが必要となるが、ボックスのサイズを2倍すれば計算時間は少なくとも8倍になってしまうのでそれは簡単ではない。自分が望むサイズにすると計算終了までとんでもない時間がかかってしまうかもしれない。<br><br>

この問題を解決する1つの方法は、多数のCPUを同時に利用できる大規模計算機を利用することである。幸い、このような計算機を効率よく利用するため、LAMMPSには並列処理版（パラレル版）が用意されている。具体的には、ボックスをいくつかの領域に分けて、それぞれの領域の処理を異なったCPUに割り当てる方式の計算法であり、領域分割法と呼ばれる。当然ながら、利用するCPU数が増えればその分計算は速くなる。<br><br>
    
またGraphics Processing Unit(GPU)を利用する並列計算法もあるが、原子間ポテンシャルの計算が加速される期待される。ただし自分の興味対象にGPU応用可能な原子間ポテンシャルが存在する必要がある。興味のある方は次の講座の<a href="gpu.html">GPUを利用する</a>でさわりだけ述べているので参考にして欲しい。<br><br>

国の研究機関や大学には<b>スーパーコンピューター（スパコン）</b>が設置されていることが多いし、その中には一般に公開されていて審査を通れば外部の人間も使えるものもある。また、スパコンのリソースを提供する業者も存在する。スパコンでは最大で1万個のCPUによる並列計算なども可能である。<br><br>

また、研究予算にもよるが、研究室専用の数100CPU程度の中規模コンピュータ（<b>クラスター計算機</b>）を導入することもいい選択肢である。<br><br>

それらは通常OSとしてLINUXが使われてれているので、 LINUX環境にパラレル版のLAMMPSのインストールしなくてはならない。しかし、一口にLINUX環境といっても様々であるので、そのことがパラレル版のインストールを少し面倒にしている。<br><br>

まず、パラレル版にはシリアル版では不要だったMessage Passing Interface (MPI)というライブラリが必要になる。これはは異なった計算ノードの壁を越えて、異なったCPU間で通信するための枠組みである。MPIはスパコンなどの大規模計算専用のマシーンにはほぼ必ずインストールされている。<br><br>

そもそも、もし研究機関のスパコンを利用するなら、もうすでにコンパイル済の並列処理版LAMMPSがあるかもしれない。なければAdministratorにコンパイル法を相談したり、お願いするという手もある。いずれにれよ、この場合のインストールはスパコンの環境に大きく依存するのでAdministratorとよく相談することだ。<br><br>

クラスター計算機を新たに導入するなら、業者にc++コンパイラ、MPI、パラレル版LAMMPSのインストールを頼んでしまえば簡単だ。<br><br>

さて、ここまでは楽な逃げ道を紹介してきたが、そもそもパラレル版LAMMPSのインストールを自力でやってもそれほど難しいことはない。ただし、さままざまケースがあるので、この講座で「この方法で全てうまくいく」という方法を紹介することができない。<br><br>
        
自分の使っていた環境では、IntelのC/C++コンパイラ、IntelのMPI、およびFFT等のライブラリが入っているMath Kernel Library(MKL)があらかじめ使用可能で、スパコンでは典型的な環境だろう。よって、必ずしも受講者の環境と同じとは限らないが、以下に紹介しておく。<br><br>

まずLAMMPSをダウンロードして展開した後、以下のような手順になる。
<pre>
<font color="green"; size="+1">
# cd [lammps top]/src
# make yes-USER-INTEL
# make intel_mpi
</font>
</pre>
最初の行でsrcディレクトリに移動する。2番目の行ではMKLなどのIntelのライブラリを追加することを指定する。最後の行は全体をコンパイル・ビルドする。因みにこの例では、[lammps top]/src/MAKEの下にMakefile.intel_mpiという名前のMakefileを予め作成してあることが前提である。<br><br>

Makefileというのは大規模コードの複雑なコンパイルを行うための手続きを記述したファイルで、それ専用の言語によって書かれている。Makefileのエキスパートになる必要はないが、大規模コードをコンパイルするにはMakefileの基本的なグラマーは習得しなくてはならない。MAKEディレクトリやそのサブディレクトリのなかに多くのMakefileの例があるので適当なものを少し改良することにより自分用のものとすることができる。決まり切った改良方法はないが、難しいことではない。コンパイルエラーが出た場合はエラーメッセージをよく読み、Makefileをさらに改良する。エラーメッセージをそのままインターネット検索にかけてもいいだろう。大体エラーが出るのはコンパイルのコマンドが違うとか、MPIとかFFTなどのライブラリがパス上に見つからないとかである。無事、コンパイルが成功すればLAMMPSの実行ファイル（実行モジュールとも言う）がsrcディレクトリ上のできる。そのファイル名はMakefileのファイル名を使って、この場合ならlmp_intel_mpiとなる。<br><br>

一般的なインストールのやり方は<a href="http://lammps.sandia.gov">公式のLAMMPSのサイト</a>に書いてあるので、それを読み解くのが一番確実だ。<br><br>

<a name="exec"><h3 style="color:Blue;">パラレル版の実行</h3></a>
次はパラレル版LAMMPSの実行である。通常並列計算機の場合、自分が作業する計算機（作業ノード）と並列計算を行う計算機（並列計算ノード）は分かれていて、作業ノードから並列計算ノードへジョブを"submit"することになる。すなわち、並列計算ノードのCPUを占有するための予約を行う。投げられたジョブを行うためのリソースが利用可能な場合には計算は直ちに始まるが、そうでない場合は順番待ちとなる。それはキューイングと呼ばれる。効率的に運営されているスパコンなら、通常計算が開始されるまで数十分程度は待たなくてはならない。<br><br>
ローカルなクラスター計算機を使っていても、やることは同じである。この場合は自分または同僚が前に投げたジョブが終わり次第、次の計算が開始されることになる。<br><br>

さて、ジョブをsubmitするためにはLINUX上で決まった形式のシェルスクリプトを作成して実行しなくてはならない。ジョブsubmitのためのシェルスクリプトはバッチスクリプトと呼ばれる。計算機によってバッチスクリプトの書き方は異なるがその概念は共通している。Portable Batch System(PBS)は多くの計算機で使われているバッチスクリプトの言語で、以下でそれを使った例を紹介する。

<pre>
<font color="green"; size="+1">
#!/bin/sh
#PBS -l nodes=4:ppn=24
#PBS -l walltime=1:00:00
#PBS -N my_lammps
cd $PBS_O_WORKDIR
mpiexec lmp_intel_mpi -in bccFe_anneal.lcm 
</font>
</pre>

ここでは1ノードあたり24コアの計算機を想定してる。その中の4ノード（すなわち96コア）を1時間占有するジョブである。オーバヘッドを無視すればシングルコアで4日程度かかる計算を行うことができる。ジョブの識別名はmy_lammpsで、パラレル版LAMMPSを実行される。計算実行はmpiexecコマンド（環境によってはmpijobやmpirunの場合あり）で行う。<br><br><br>

<center>********</center><br>

さて、ここまで紹介してきたようなスパコンやクラスター計算機などの大規模な計算機が使えない場合はどうしたらいいだろう。正直、大きな効果は期待できないが自分の事務用PCでも昨今は少なくとも8CPUはある。別に動いているプロセスもあるのですべてのCPUを占有できるわけではないが、少しでも作業を効率化したいなら、そこでパラレル版を利用すべきだ。<br><br>

ちなみにWindowsやMacOSへのインストールは先に説明した<a href="install.html">インストールの講座</a>にもどり、この中のインストール法が紹介されているリンクを参考にすればよい。Macでは初めからMPIが入っており、パラレル版はシリアル版と同時にインストールされるので手間はかからない。<br><br>

実行は上記のジョブsubmitではなくコマンドラインで行う。8並列で計算したいなら以下のようなコマンドラインで実行する。
<pre>
<font color="green"; size="+1">
$ mpiexec -np 8 lmp_mpi -in bccFe_anneal.lcm 
</font>
</pre>

<pre>
----------------------------------------------------
</pre>
<a href="index.html">目次へ</a>    前は<a href="read_data.html">LAMMPSの外部で初期値を作る</a>  次は<a href="gpu.html">GPUを利用する</a></pre>
<br><br>
</body>
</html>
